{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"TensorArrayReadV3_2:0\", shape=(?, 300), dtype=float32)\n",
      "Tensor(\"add_24:0\", shape=(5, 2), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(5, 300), dtype=float32)\n",
      "Tensor(\"transpose_7:0\", shape=(5, ?, 300), dtype=float32)\n",
      "Tensor(\"Gather_3:0\", shape=(?, 10, 300), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import seq2seq\n",
    "from seq2seq.models import AttentionSeq2Seq, SimpleSeq2Seq, Seq2Seq\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "path = 'data/'\n",
    "\n",
    "with open(path+\"word_index_conversion.p\",'rb') as f:\n",
    "    word_index_conversion = pickle.load(f)\n",
    "    \n",
    "word2index = word_index_conversion['word2index']\n",
    "index2word = word_index_conversion['index2word']\n",
    "\n",
    "lookup_matrix = np.load(path+'word2vec.npy')\n",
    "\n",
    "# lookup_matrix = np.zeros((100,20))\n",
    "\n",
    "sentences = np.load(path+'sentences_as_list.npy')\n",
    "\n",
    "filtered_sentences = [filter(lambda x:word2index.has_key(x), s) for s in sentences]\n",
    "# Filter out sentences with length larger than 2\n",
    "filtered_sentences = filter(lambda x:len(x) > 2, filtered_sentences)\n",
    "\n",
    "idxes = [[word2index[w] for w in s] for s in filtered_sentences]\n",
    "\n",
    "# Constants\n",
    "batch_size = 5\n",
    "time_steps = 10\n",
    "embedding_size = lookup_matrix.shape[1]\n",
    "latent_dim = 2\n",
    "hidden_dim = 256\n",
    "epochs = 50\n",
    "epsilon_std = 1.0\n",
    "time_steps = 10\n",
    "epsilon_std = 1\n",
    "\n",
    "padded_idxes = pad_sequences(idxes, maxlen=time_steps, dtype='int32', \\\n",
    "                                 padding='pre', truncating='pre', value=0.)\n",
    "\n",
    "x_train, x_test = train_test_split(padded_idxes, test_size=0.2, random_state=42)\n",
    "\n",
    "# x_train, x_test = np.zeros((50,time_steps)), np.zeros((10,time_steps))\n",
    "\n",
    "optimizer, loss, x, y = SimpleSeq2Seq(output_dim=embedding_size, output_length=time_steps, latent_dim=latent_dim, \\\n",
    "                                      batch_size=batch_size, epsilon_std=epsilon_std, lookup_matrix=lookup_matrix, \\\n",
    "                                      input_shape=(time_steps, embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1058728, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:0\n",
      "0.0622273\n",
      "0.0443519\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8e4dab250ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xupengtong/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xupengtong/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xupengtong/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/xupengtong/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xupengtong/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    epochs = 0\n",
    "    print_freq = 15\n",
    "    while epochs < 30:\n",
    "        print \"Epochs:\" + str(epochs)\n",
    "        i = 0\n",
    "        while i < len(x_train):\n",
    "            samples = x_train[i:i+batch_size,:]\n",
    "            i += batch_size\n",
    "            _, loss_val = sess.run([optimizer, loss], feed_dict={x:samples, y:samples})\n",
    "            if i % print_freq == 0:\n",
    "                print loss_val\n",
    "        epochs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SimpleSeq2Seq(output_dim=embedding_size, output_length=time_steps, input_shape=(time_steps, embedding_size))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(x_train_embedded, x_train_embedded, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_length = 10\n",
    "input_dim = 2\n",
    "\n",
    "output_length = 8\n",
    "output_dim = 3\n",
    "\n",
    "samples = 100\n",
    "\n",
    "x = np.random.random((samples, input_length, input_dim))\n",
    "y = np.random.random((samples, output_length, output_dim))\n",
    "\n",
    "lookup_matrix\n",
    "\n",
    "models = []\n",
    "models += [SimpleSeq2Seq(output_dim=output_dim, output_length=output_length, input_shape=(input_length, input_dim))]\n",
    "models += [SimpleSeq2Seq(output_dim=output_dim, output_length=output_length, input_shape=(input_length, input_dim), depth=2)]\n",
    "\n",
    "for model in models:\n",
    "    model.compile(loss='mse', optimizer='sgd')\n",
    "    model.fit(x, y, nb_epoch=1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd')\n",
    "model.fit(x_train, x_train, nb_epoch=1, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_length = 10\n",
    "input_dim = 2\n",
    "\n",
    "output_length = 8\n",
    "output_dim = 3\n",
    "\n",
    "samples = 100\n",
    "\n",
    "model = AttentionSeq2Seq(output_dim=output_dim, output_length=output_length, input_shape=(input_length, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Input(batch_shape=(batch_size, time_steps))\n",
    "x = Embedding(input_dim=lookup_matrix.shape[0], output_dim=lookup_matrix.shape[1], weights=[lookup_matrix])(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "h_encoded = LSTM(hidden_dim, batch_input_shape=(batch_size, time_steps, embedding_size), \\\n",
    "                     return_sequences=False, stateful=True)(x)\n",
    "\n",
    "z_mean = Dense(latent_dim)(h_encoded)\n",
    "z_log_var = Dense(latent_dim)(h_encoded)\n",
    "\n",
    "# # build a model to project inputs on the latent space\n",
    "# encoder = Model(x, z_mean)\n",
    "\n",
    "# # display a 2D plot of the digit classes in the latent space\n",
    "# x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# # build a digit generator that can sample from the learned distribution\n",
    "# decoder_input = Input(shape=(latent_dim,))\n",
    "# _h_decoded = decoder_h(decoder_input)\n",
    "# _x_decoded_mean = decoder_mean(_h_decoded)\n",
    "# generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "# # display a 2D manifold of the digits\n",
    "# n = 15  # figure with 15x15 digits\n",
    "# digit_size = 28\n",
    "# figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# # linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# # to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "# grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "# grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "# for i, yi in enumerate(grid_x):\n",
    "#     for j, xi in enumerate(grid_y):\n",
    "#         z_sample = np.array([[xi, yi]])\n",
    "#         x_decoded = generator.predict(z_sample)\n",
    "#         digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "#         figure[i * digit_size: (i + 1) * digit_size,\n",
    "#                j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(figure, cmap='Greys_r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args         \n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "h_0 = Dense(hidden_dim, activation='relu')(z)\n",
    "h_decoded = LSTM(embedding_size, batch_input_shape=(batch_size, time_steps, hidden_dim), \\\n",
    "                     return_sequences=True, stateful=True)(h_0)\n",
    "\n",
    "x_decoded_mean = Dense(original_dim, activation='sigmoid')(h_decoded)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='adam', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(36,))\n",
    "x = Embedding(input_dim=lookup_matrix.shape[0], output_dim=lookup_matrix.shape[1], weights=[lookup_matrix])(input_tensor)\n",
    "\n",
    "model = Model(input=[input_tensor], output=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sess.run(init)\n",
    "\n",
    "temp = sess.run(h_encoded, feed_dict={model.input:padded_idxes[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Lambda, LSTM\n",
    "\n",
    "batch_size = 10\n",
    "time_steps = 36\n",
    "embedding_size = 300\n",
    "\n",
    "h_encoded = LSTM(10, input_shape=(time_steps, embedding_size), \\\n",
    "                     return_sequences=True, stateful=False)(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
